{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252de0de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker fine tune ChatGLM\n",
    "\n",
    "#### 准备\n",
    "1. 升级boto3, sagemaker python sdk  \n",
    "2. 准备requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f2c403",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.26.116)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.121-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3) (0.6.0)\n",
      "Collecting botocore<1.30.0,>=1.29.121\n",
      "  Downloading botocore-1.29.121-py3-none-any.whl (10.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.121->boto3) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.121->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.121->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.116\n",
      "    Uninstalling botocore-1.29.116:\n",
      "      Successfully uninstalled botocore-1.29.116\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.116\n",
      "    Uninstalling boto3-1.26.116:\n",
      "      Successfully uninstalled boto3-1.26.116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.71 requires botocore==1.29.71, but you have botocore 1.29.121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.121 botocore-1.29.121\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.148.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.150.0.tar.gz (747 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m747.7/747.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (22.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.26.121)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.4.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (5.4.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (2.6.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.121 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.29.121)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema->sagemaker) (65.6.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2022.7)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.121->boto3<2.0,>=1.26.28->sagemaker) (1.26.8)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.150.0-py2.py3-none-any.whl size=1003414 sha256=716f29ce2c913c739beaabb2a5372073c4659b886e4c46a2fdea9621cbabc90c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b3/d5/a6/017b77588f0e7ea52690b1866a4cde2f6ad7681ccd5c5d9aec\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.148.0\n",
      "    Uninstalling sagemaker-2.148.0:\n",
      "      Successfully uninstalled sagemaker-2.148.0\n",
      "Successfully installed sagemaker-2.150.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4a30f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker-us-west-2-687912291502\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbcac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chatglm 官方P-tuning v2方式（单机单卡）\n",
    "1:安装依赖lib   \n",
    "2:准备数据集(本例以ADGEN 文本生成数据集为例，将解压后的 AdvertiseGen 目录放到本目录  \n",
    "3:修改并bash运行 train.sh  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07fa0a4-8e21-4441-a9b4-3a038f6c5cd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ChatGLM-6B/requirements.txt (line 1)) (3.20.2)\n",
      "Collecting transformers==4.27.1\n",
      "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cpm_kernels\n",
      "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ChatGLM-6B/requirements.txt (line 4)) (1.13.1)\n",
      "Collecting gradio\n",
      "  Downloading gradio-3.27.0-py3-none-any.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdtex2html\n",
      "  Downloading mdtex2html-1.2.0-py3-none-any.whl (13 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (0.14.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (4.63.2)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.10->-r ChatGLM-6B/requirements.txt (line 4)) (4.4.0)\n",
      "Collecting gradio-client>=0.1.3\n",
      "  Downloading gradio_client-0.1.3-py3-none-any.whl (286 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.2/286.2 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (3.8.3)\n",
      "Collecting altair>=4.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markupsafe in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (3.5.3)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (9.2.0)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-11.0.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.10.4)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson\n",
      "  Downloading orjson-3.8.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r ChatGLM-6B/requirements.txt (line 5)) (3.1.2)\n",
      "Collecting semantic-version\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting latex2mathml\n",
      "  Downloading latex2mathml-3.75.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate->-r ChatGLM-6B/requirements.txt (line 8)) (5.9.4)\n",
      "Requirement already satisfied: toolz in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (0.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio-client>=0.1.3->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (2022.11.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (2022.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (4.0.2)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (2022.12.7)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown->mdtex2html->-r ChatGLM-6B/requirements.txt (line 6)) (4.13.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.27.1->-r ChatGLM-6B/requirements.txt (line 2)) (1.26.8)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from uvicorn->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (3.6.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown->mdtex2html->-r ChatGLM-6B/requirements.txt (line 6)) (3.11.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (0.19.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r ChatGLM-6B/requirements.txt (line 5)) (65.6.3)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=1274f6b04d20c9178156705e38f644cc766c1d2ea94f071096b344b798c2c0f3\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/8d/02/a5/43ebb208903df15c239ac247db73fa9483efb792f74a0e445a\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: tokenizers, sentencepiece, pydub, ffmpy, cpm_kernels, websockets, uc-micro-py, semantic-version, python-multipart, orjson, mdurl, latex2mathml, h11, aiofiles, uvicorn, starlette, markdown-it-py, markdown, linkify-it-py, httpcore, accelerate, transformers, mdtex2html, mdit-py-plugins, httpx, fastapi, altair, gradio-client, gradio\n",
      "Successfully installed accelerate-0.18.0 aiofiles-23.1.0 altair-4.2.2 cpm_kernels-1.0.11 fastapi-0.95.1 ffmpy-0.3.0 gradio-3.27.0 gradio-client-0.1.3 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 latex2mathml-3.75.3 linkify-it-py-2.0.0 markdown-3.4.3 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdtex2html-1.2.0 mdurl-0.1.2 orjson-3.8.10 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 sentencepiece-0.1.98 starlette-0.26.1 tokenizers-0.13.3 transformers-4.27.1 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install rouge_chinese nltk jieba datasets\n",
    "#!git clone https://github.com/THUDM/ChatGLM-6B.git\n",
    "!pip install -r ChatGLM-6B/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ca76f3d-e961-4c4c-84cc-6ea297711a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp ChatGLM-6B/ptuning/AdvertiseGen/dev.json s3://sagemaker-us-west-2-687912291502/llm/chatglm/datasets/dev.json\n",
      "cp ChatGLM-6B/ptuning/AdvertiseGen/train.json s3://sagemaker-us-west-2-687912291502/llm/chatglm/datasets/train.json\n"
     ]
    }
   ],
   "source": [
    "#!cd ChatGLM-6B/ptuning/ && wget \"https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1\"\n",
    "#!cd ChatGLM-6B/ptuning/ && mv \"index.html?dl=1\" dataset.tar.gz\n",
    "#!cd ChatGLM-6B/ptuning/ && tar -xvf dataset.tar.gz\n",
    "!./ChatGLM-6B/ptuning/s5cmd sync ChatGLM-6B/ptuning/AdvertiseGen/ s3://{bucket}/llm/chatglm/datasets/ \n",
    "#!rm -rf cd ChatGLM-6B/ptuning/dataset.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8a09a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27/2023 09:11:17 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "04/27/2023 09:11:17 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.02,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=output/adgen-chatglm-6b-pt-128-2e-2/runs/Apr27_09-11-17_ip-172-16-82-196.us-west-2.compute.internal,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=300,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=output/adgen-chatglm-6b-pt-128-2e-2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output/adgen-chatglm-6b-pt-128-2e-2,\n",
      "save_on_each_node=False,\n",
      "save_steps=300,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/27/2023 09:11:17 - WARNING - datasets.builder - Found cached dataset json (/home/ec2-user/.cache/huggingface/datasets/json/default-1e7622c3b4e29de4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 642.02it/s]\n",
      "[INFO|configuration_utils.py:668] 2023-04-27 09:11:18,027 >> loading configuration file config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/config.json\n",
      "[WARNING|configuration_auto.py:905] 2023-04-27 09:11:18,027 >> Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "[INFO|configuration_utils.py:668] 2023-04-27 09:11:18,416 >> loading configuration file config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-27 09:11:18,417 >> Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm-6b\",\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\"\n",
      "  },\n",
      "  \"bos_token_id\": 130004,\n",
      "  \"eos_token_id\": 130005,\n",
      "  \"gmask_token_id\": 130001,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"inner_hidden_size\": 16384,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"mask_token_id\": 130000,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"position_encoding_2d\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 130528\n",
      "}\n",
      "\n",
      "[WARNING|tokenization_auto.py:652] 2023-04-27 09:11:18,503 >> Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-27 09:11:18,755 >> loading file ice_text.model from cache at /home/ec2-user/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/ice_text.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-27 09:11:18,755 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-27 09:11:18,755 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-27 09:11:18,755 >> loading file tokenizer_config.json from cache at /home/ec2-user/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/tokenizer_config.json\n",
      "[WARNING|auto_factory.py:456] 2023-04-27 09:11:19,003 >> Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "[INFO|modeling_utils.py:2403] 2023-04-27 09:11:19,849 >> loading weights file pytorch_model.bin from cache at /home/ec2-user/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/pytorch_model.bin.index.json\n",
      "[INFO|configuration_utils.py:575] 2023-04-27 09:11:19,851 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 130004,\n",
      "  \"eos_token_id\": 130005,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"transformers_version\": \"4.27.1\"\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:09<00:00,  1.15s/it]\n",
      "[INFO|modeling_utils.py:3032] 2023-04-27 09:11:29,359 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.\n",
      "\n",
      "[WARNING|modeling_utils.py:3034] 2023-04-27 09:11:29,359 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at THUDM/chatglm-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|modeling_utils.py:2690] 2023-04-27 09:11:29,491 >> Generation config file not found, using a generation config created from the model config.\n",
      "Quantized to 4 bit\n",
      "input_ids [5, 65421, 61, 67329, 32, 98339, 61, 72043, 32, 65347, 61, 70872, 32, 69768, 61, 68944, 32, 67329, 64103, 61, 96914, 130001, 130004, 5, 87052, 96914, 81471, 64562, 65759, 64493, 64988, 6, 65840, 65388, 74531, 63825, 75786, 64009, 63823, 65626, 63882, 64619, 65388, 6, 64480, 65604, 85646, 110945, 10, 64089, 65966, 87052, 67329, 65544, 6, 71964, 70533, 64417, 63862, 89978, 63991, 63823, 77284, 88473, 64219, 63848, 112012, 6, 71231, 65099, 71252, 66800, 85768, 64566, 64338, 100323, 75469, 63823, 117317, 64218, 64257, 64051, 74197, 6, 63893, 130005, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "inputs 类型#裤*版型#宽松*风格#性感*图案#线条*裤型#阔腿裤 宽松的阔腿裤这两年真的吸粉不少,明星时尚达人的心头爱。毕竟好穿时尚,谁都能穿出腿长2米的效果宽松的裤腿,当然是遮肉小能手啊。上身随性自然不拘束,面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点,还\n",
      "label_ids [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 130004, 5, 87052, 96914, 81471, 64562, 65759, 64493, 64988, 6, 65840, 65388, 74531, 63825, 75786, 64009, 63823, 65626, 63882, 64619, 65388, 6, 64480, 65604, 85646, 110945, 10, 64089, 65966, 87052, 67329, 65544, 6, 71964, 70533, 64417, 63862, 89978, 63991, 63823, 77284, 88473, 64219, 63848, 112012, 6, 71231, 65099, 71252, 66800, 85768, 64566, 64338, 100323, 75469, 63823, 117317, 64218, 64257, 64051, 74197, 6, 63893, 130005, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "labels 宽松的阔腿裤这两年真的吸粉不少,明星时尚达人的心头爱。毕竟好穿时尚,谁都能穿出腿长2米的效果宽松的裤腿,当然是遮肉小能手啊。上身随性自然不拘束,面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点,还\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                   | 0/300 [00:00<?, ?it/s]04/27/2023 09:15:02 - WARNING - transformers_modules.THUDM.chatglm-6b.a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd.modeling_chatglm - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "{'loss': 5.1745, 'learning_rate': 0.019333333333333334, 'epoch': 0.0}           \n",
      "{'loss': 4.5993, 'learning_rate': 0.018666666666666668, 'epoch': 0.0}           \n",
      "{'loss': 4.5411, 'learning_rate': 0.018000000000000002, 'epoch': 0.0}           \n",
      "{'loss': 4.348, 'learning_rate': 0.017333333333333336, 'epoch': 0.01}           \n",
      "{'loss': 4.3562, 'learning_rate': 0.016666666666666666, 'epoch': 0.01}          \n",
      "{'loss': 4.2723, 'learning_rate': 0.016, 'epoch': 0.01}                         \n",
      "{'loss': 4.3071, 'learning_rate': 0.015333333333333334, 'epoch': 0.01}          \n",
      "{'loss': 4.2592, 'learning_rate': 0.014666666666666666, 'epoch': 0.01}          \n",
      "{'loss': 4.2857, 'learning_rate': 0.013999999999999999, 'epoch': 0.01}          \n",
      "{'loss': 4.3017, 'learning_rate': 0.013333333333333332, 'epoch': 0.01}          \n",
      "{'loss': 4.407, 'learning_rate': 0.012666666666666666, 'epoch': 0.02}           \n",
      "{'loss': 4.3251, 'learning_rate': 0.012, 'epoch': 0.02}                         \n",
      "{'loss': 4.1959, 'learning_rate': 0.011333333333333332, 'epoch': 0.02}          \n",
      "{'loss': 4.2457, 'learning_rate': 0.010666666666666666, 'epoch': 0.02}          \n",
      "{'loss': 4.2632, 'learning_rate': 0.01, 'epoch': 0.02}                          \n",
      "{'loss': 4.2607, 'learning_rate': 0.009333333333333334, 'epoch': 0.02}          \n",
      "{'loss': 4.2509, 'learning_rate': 0.008666666666666668, 'epoch': 0.02}          \n",
      "{'loss': 4.2292, 'learning_rate': 0.008, 'epoch': 0.03}                         \n",
      "{'loss': 4.2908, 'learning_rate': 0.007333333333333333, 'epoch': 0.03}          \n",
      "{'loss': 4.196, 'learning_rate': 0.006666666666666666, 'epoch': 0.03}           \n",
      "{'loss': 4.2148, 'learning_rate': 0.006, 'epoch': 0.03}                         \n",
      "{'loss': 4.2693, 'learning_rate': 0.005333333333333333, 'epoch': 0.03}          \n",
      "{'loss': 4.1732, 'learning_rate': 0.004666666666666667, 'epoch': 0.03}          \n",
      "{'loss': 4.2286, 'learning_rate': 0.004, 'epoch': 0.03}                         \n",
      "{'loss': 4.1814, 'learning_rate': 0.003333333333333333, 'epoch': 0.03}          \n",
      "{'loss': 4.2129, 'learning_rate': 0.0026666666666666666, 'epoch': 0.04}         \n",
      "{'loss': 4.1679, 'learning_rate': 0.002, 'epoch': 0.04}                         \n",
      "{'loss': 4.3041, 'learning_rate': 0.0013333333333333333, 'epoch': 0.04}         \n",
      "{'loss': 4.2133, 'learning_rate': 0.0006666666666666666, 'epoch': 0.04}         \n",
      "{'loss': 4.1121, 'learning_rate': 0.0, 'epoch': 0.04}                           \n",
      "100%|█████████████████████████████████████████| 300/300 [56:48<00:00, 11.57s/it]Saving PrefixEncoder\n",
      "[INFO|configuration_utils.py:457] 2023-04-27 10:11:51,803 >> Configuration saved in output/adgen-chatglm-6b-pt-128-2e-2/checkpoint-300/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-27 10:11:51,805 >> Configuration saved in output/adgen-chatglm-6b-pt-128-2e-2/checkpoint-300/generation_config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-04-27 10:11:51,998 >> Model weights saved in output/adgen-chatglm-6b-pt-128-2e-2/checkpoint-300/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-04-27 10:11:51,999 >> tokenizer config file saved in output/adgen-chatglm-6b-pt-128-2e-2/checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-27 10:11:51,999 >> Special tokens file saved in output/adgen-chatglm-6b-pt-128-2e-2/checkpoint-300/special_tokens_map.json\n",
      "{'train_runtime': 3409.4339, 'train_samples_per_second': 1.408, 'train_steps_per_second': 0.088, 'train_loss': 4.306236979166667, 'epoch': 0.04}\n",
      "100%|█████████████████████████████████████████| 300/300 [56:49<00:00, 11.36s/it]\n",
      "***** train metrics *****\n",
      "  epoch                    =       0.04\n",
      "  train_loss               =     4.3062\n",
      "  train_runtime            = 0:56:49.43\n",
      "  train_samples            =     114599\n",
      "  train_samples_per_second =      1.408\n",
      "  train_steps_per_second   =      0.088\n"
     ]
    }
   ],
   "source": [
    "!cd ChatGLM-6B/ptuning/&& bash train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130efd9",
   "metadata": {},
   "source": [
    "### chatglm 官方deepspeed方式（全参数的Finetune,单机多卡）\n",
    "1: 准备deepspeed lib，并修改deepspeed.json    \n",
    "2：数据集（以上一致）  \n",
    "3：entrypoint start.py,设置deepspeed hosts configure\n",
    "4：触发bash ds_train_finetune.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9436071c-6e98-4b38-aff8-507193445382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 4176k  100 4176k    0     0  14.7M      0 --:--:-- --:--:-- --:--:-- 14.7M\n"
     ]
    }
   ],
   "source": [
    "#print('s3://{}/llm/models/'.format(sagemaker_session.default_bucket()))\n",
    "#!aws s3 ls s3://sagemaker-us-west-2-687912291502/llm/models/\n",
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz && mv s5cmd ChatGLM-6B/ptuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43238d1d-36b8-427f-809f-591a44461af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processes_per_host is set to: 8\n"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.p4d.24xlarge'\n",
    "if instance_type in [\n",
    "    \"ml.p3.16xlarge\",\n",
    "    \"ml.p3dn.24xlarge\",\n",
    "    \"ml.g5.48xlarge\",\n",
    "    \"ml.p4d.24xlarge\",\n",
    "]:\n",
    "    processes_per_host = 8\n",
    "elif instance_type == \"ml.p2.16xlarge\":\n",
    "    processes_per_host = 16\n",
    "else:\n",
    "    processes_per_host = 4\n",
    "\n",
    "print(\"processes_per_host is set to:\", processes_per_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f648f6-7a86-4d18-a087-37401bdd2188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define Training Job Name \n",
    "job_name = f'huggingface-chatglm-deepspeed-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "#define the model s3 path which will store your trained model asset\n",
    "#Note: you should use your real s3 path to configure model_s3_path\n",
    "model_s3_path='s3://{}/llm/models/chatglm/deepspeed/'.format(sagemaker_session.default_bucket())\n",
    "output_dir = '/opt/ml/model/adgen-chatglm-6b-ft'\n",
    "model_name_or_path = 'THUDM/chatglm-6b'\n",
    "\n",
    "\n",
    "instance_count = 2\n",
    "#define the enviroment variables for your scripts.\n",
    "environment = {\n",
    "              'MODEL_S3_PATH'          : model_s3_path,\n",
    "              'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:32',\n",
    "              'LD_LIBRARY_PATH'        : '${LD_LIBRARY_PATH}:/opt/conda/lib/',\n",
    "              'NUM_GPUS'               : processes_per_host，\n",
    "              'TRAIN_DATASET'          : '/opt/ml/input/data/AdvertiseGen/train.json',\n",
    "              'TEST_DATASET'           : '/opt/ml/input/data/AdvertiseGen/dev.json',\n",
    "              'PROMPT_COLUMN'          : 'content',\n",
    "              'RESPONSE_COLUMN'        : 'summary',\n",
    "              'MODEL_NAME_OR_PATH'     : model_name_or_path,\n",
    "              'OUTPUT_DIR'             : output_dir,\n",
    "              'MODEL_OUTPUT_S3_PATH'   : model_s3_path\n",
    "}\n",
    "\n",
    "inputs={\n",
    "   'AdvertiseGen': f\"s3://{bucket}/llm/chatglm/datasets/\"\n",
    "}\n",
    "\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'start.py',          # user endpoint script\n",
    "    source_dir           = 'ChatGLM-6B/ptuning',               # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type, # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    environment = environment,\n",
    ")\n",
    "huggingface_estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2ea36-1308-4919-8338-0bbb7cb2fa07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
