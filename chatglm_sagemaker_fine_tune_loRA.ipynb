{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252de0de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker fine tune ChatGLM\n",
    "\n",
    "#### 准备\n",
    "1. 升级boto3, sagemaker python sdk  \n",
    "2. 准备requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f2c403",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.26.71)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.116-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3) (0.6.0)\n",
      "Collecting botocore<1.30.0,>=1.29.116\n",
      "  Downloading botocore-1.29.116-py3-none-any.whl (10.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.116->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.116->boto3) (1.26.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.116->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.71\n",
      "    Uninstalling botocore-1.29.71:\n",
      "      Successfully uninstalled botocore-1.29.71\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.71\n",
      "    Uninstalling boto3-1.26.71:\n",
      "      Successfully uninstalled boto3-1.26.71\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.71 requires botocore==1.29.71, but you have botocore 1.29.116 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.116 botocore-1.29.116\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.132.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.148.0.tar.gz (743 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m743.3/743.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (22.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.26.116)\n",
      "Collecting cloudpickle==2.2.1\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.4.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (5.4.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (2.6.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.116 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.29.116)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema->sagemaker) (65.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2022.7)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.116->boto3<2.0,>=1.26.28->sagemaker) (1.26.8)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.148.0-py2.py3-none-any.whl size=998496 sha256=60972853c9019b0256fc91cbb9a01495e4e968902662ea7a9093c45a60210476\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/66/36/07/56de705f4ad8ea09e40419f57f8478bc60aae5b1e095dda1f0\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: cloudpickle, sagemaker\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.0\n",
      "    Uninstalling cloudpickle-2.2.0:\n",
      "      Successfully uninstalled cloudpickle-2.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.132.0\n",
      "    Uninstalling sagemaker-2.132.0:\n",
      "      Successfully uninstalled sagemaker-2.132.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.11.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cloudpickle-2.2.1 sagemaker-2.148.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a30f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker-us-west-2-687912291502\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f59e3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### chatglm lora方式（simple_thu_chatglm6b单机单卡）\n",
    "1: 使用羊驼语料数据  \n",
    "2：语料处理，tokenization及label标注  \n",
    "3：HF trainer API  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2f288-0610-4b18-9409-c8ef5ee91ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hikariming/alpaca_chinese_dataset.git\n",
    "!git clone https://github.com/yuanzhoulvpi2017/zero_nlp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6bc6f4-152e-4697-9c5b-0174bb17b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os \n",
    "import pandas as pd \n",
    "import shutil\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f217e-c0c6-428b-ab10-50927e74c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir_list = ['alpaca_chinese_dataset/其他中文问题补充/',\n",
    "                   'alpaca_chinese_dataset/翻译后的中文数据/',\n",
    "                   'alpaca_chinese_dataset/chatglm问题数据补充/',\n",
    "                #    'alpaca_chinese_dataset/原始英文数据/'\n",
    "                   ]\n",
    "\n",
    "all_json_path = [glob(i+\"*.json\") for i in target_dir_list]\n",
    "all_json_path = list(chain(*all_json_path))\n",
    "len(all_json_path), all_json_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81470514-d789-47cc-9b2f-602bcb4f2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(x:str):\n",
    "    try:\n",
    "        data = pd.read_json(x)\n",
    "        return data \n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "alldata = pd.concat([read_json(i) for i in all_json_path])\n",
    "# alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118994f5-1b0f-4163-95ef-a1fef4b42002",
   "metadata": {},
   "outputs": [],
   "source": [
    "genrate_data_dir = \"data3_0328\"\n",
    "genrate_data_dir = Path(genrate_data_dir)\n",
    "\n",
    "if genrate_data_dir.exists():\n",
    "    shutil.rmtree(genrate_data_dir, ignore_errors=True)\n",
    "\n",
    "os.makedirs(genrate_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a128d-cbe3-4892-bbcc-1868e89d333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = alldata.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "chunk_size = 666\n",
    "\n",
    "for index, start_id in tqdm(enumerate(range(0, alldata.shape[0], chunk_size))):\n",
    "    temp_data = alldata.iloc[start_id:(start_id+chunk_size)]\n",
    "    temp_data.to_csv(genrate_data_dir.joinpath(f\"{index}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e3381-73c3-46be-8064-1b5490fa0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from thuglm.modeling_chatglm import ChatGLMForConditionalGeneration\n",
    "# from thuglmcode.model_chatglm import ChatGLMForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from typing import Optional\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4a012-3cd6-4c58-b382-0c6cf739ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"yuanzhoulvpi/chatglm6b-dddd\", trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"yuanzhoulvpi/chatglm6b-dddd\", trust_remote_code=True).half().cuda()\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1,\n",
    "    # ['dense','dense_h_to_4h','dense_4h_to_h'] # 'query_key_value',\n",
    "    target_modules=['query_key_value',],\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def _save(self, output_dir: Optional[str] = None, state_dict=None):\n",
    "        # If we are executing this function, we are the process zero, so we don't check for that.\n",
    "        output_dir = output_dir if output_dir is not None else self.args.output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        def save_tunable_parameters(model, path):\n",
    "            saved_params = {\n",
    "                k: v.to(\"cpu\") for k, v in model.named_parameters() if v.requires_grad\n",
    "            }\n",
    "            # saved_params = model.state_dict()\n",
    "            torch.save(saved_params, path)\n",
    "\n",
    "        save_tunable_parameters(\n",
    "            self.model, os.path.join(output_dir, \"chatglm-lora.pt\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c1bbd-caaf-43fa-b3a8-8e74dfe44474",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "all_file_list = glob(pathname=genrate_data_dir.joinpath(\"*.csv\").__str__())\n",
    "\n",
    "test_file_list = random.sample(all_file_list, int(len(all_file_list)*0.25))\n",
    "train_file_list = [i for i in all_file_list if i not in test_file_list]\n",
    "\n",
    "len(train_file_list), len(test_file_list)\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "    'train':train_file_list,\n",
    "    'valid':test_file_list\n",
    "    },\n",
    "    cache_dir=\"cache_data\"\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867116c-49fd-4ad9-a57e-04aef84b0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks_and_position_ids(\n",
    "    seq, seq_len, context_length, device, gmask=False, position_encoding_2d=True\n",
    "):\n",
    "    mask_position = (\n",
    "        seq_len - 2\n",
    "    )  # is equal to `seq.index(mask_token)` or `seq.index(150001)`\n",
    "    attention_mask = torch.ones((1, context_length, context_length), device=device)\n",
    "    attention_mask.tril_()\n",
    "    attention_mask[..., : mask_position - 1] = 1\n",
    "    attention_mask = (attention_mask < 0.5).bool()\n",
    "\n",
    "    if position_encoding_2d:\n",
    "        seq_length = seq_len - 1  # is equal to `seq_length = seq.index(150004)`\n",
    "        position_ids = torch.arange(context_length, dtype=torch.long, device=device)\n",
    "        if not gmask:\n",
    "            position_ids[seq_length:] = mask_position\n",
    "        block_position_ids = torch.cat(\n",
    "            (\n",
    "                torch.zeros(seq_length, dtype=torch.long, device=device),\n",
    "                torch.arange(\n",
    "                    context_length - seq_length, dtype=torch.long, device=device\n",
    "                )\n",
    "                + 1,\n",
    "            )\n",
    "        )\n",
    "        position_ids = torch.stack((position_ids, block_position_ids), dim=0)\n",
    "    else:\n",
    "        position_ids = torch.arange(context_length, dtype=torch.long, device=device)\n",
    "        if not gmask:\n",
    "            position_ids[context_length - 1 :] = mask_position\n",
    "    return attention_mask, position_ids\n",
    "\n",
    "def data_collator(features: list) -> dict:\n",
    "    len_ids = [len(feature[\"input_ids\"]) for feature in features]\n",
    "    longest = max(len_ids) + 1\n",
    "    input_ids = []\n",
    "    attention_mask_list = []\n",
    "    position_ids_list = []\n",
    "    labels_list = []\n",
    "    for ids_l, feature in sorted(zip(len_ids, features), key=lambda x: -x[0]):\n",
    "        ids = feature[\"input_ids\"]\n",
    "        seq_len = feature[\"seq_len\"]\n",
    "        labels = (\n",
    "            [-100] * (seq_len - 1)\n",
    "            + ids[(seq_len - 1) :]\n",
    "            + [tokenizer.eop_token_id]\n",
    "            + [-100] * (longest - ids_l - 1)\n",
    "        )\n",
    "        ids = ids + [tokenizer.eop_token_id] * (longest - ids_l)\n",
    "        _ids = torch.LongTensor(ids)\n",
    "        attention_mask, position_ids = get_masks_and_position_ids(\n",
    "            ids, seq_len, longest, _ids.device, gmask=False\n",
    "        )\n",
    "        labels_list.append(torch.LongTensor(labels))\n",
    "        input_ids.append(_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        position_ids_list.append(position_ids)\n",
    "    input_ids = torch.stack(input_ids)\n",
    "    labels = torch.stack(labels_list)\n",
    "    attention_mask = torch.stack(attention_mask_list)\n",
    "    position_ids = torch.stack(position_ids_list)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"position_ids\": position_ids,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3d501-8b24-4be0-a583-f95593914f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    # {\"context\": context, \"target\": target}\n",
    "    example['context'] = context\n",
    "    example['target'] = target\n",
    "    return example\n",
    "\n",
    "max_seq_length = 512\n",
    "\n",
    "def preprocess(example):\n",
    "    prompt = example[\"context\"]\n",
    "    target = example[\"target\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True)\n",
    "    target_ids = tokenizer.encode(\n",
    "        target, max_length=max_seq_length, truncation=True, add_special_tokens=False\n",
    "    )\n",
    "    input_ids = prompt_ids + target_ids + [tokenizer.eos_token_id]\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}\n",
    "\n",
    "def filter_nan(example):\n",
    "    return example['target'] is not None and example['context'] is not  None\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    function=format_example, remove_columns=dataset['train'].column_names\n",
    "    ).filter(function=filter_nan)\n",
    "tokenized_datasets = tokenized_datasets.map(function=preprocess)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f99b08-25d8-48ac-aafa-603744c3f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_callback import TrainerCallback, TrainerState, TrainerControl\n",
    "\n",
    "\n",
    "\n",
    "class EmptyCacheCallBack(TrainerCallback):\n",
    "    \"\"\"\n",
    "    通过callback的形式，解决显存不够的问题\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs, **kwargs):\n",
    "        \"\"\"\n",
    "        Event called after logging the last logs.\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def on_epoch_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def on_step_begin(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "\n",
    "eccb = EmptyCacheCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b17418-615c-4107-9868-aa915c27695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"test004\",\n",
    "    per_device_train_batch_size=2, \n",
    "    per_device_eval_batch_size=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    logging_steps=50,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=100,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = MyTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "    # callbacks=[eccb]\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff62875-5b26-47a8-8444-00da95780a51",
   "metadata": {},
   "source": [
    "### chatglm lora方式（单机多卡、模型并行）\n",
    "与单机单卡训练类似，使用pytorch ddp+lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da3b52-414b-429c-b261-7133d172aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('s3://{}/llm/models/'.format(sagemaker_session.default_bucket()))\n",
    "#!aws s3 ls s3://sagemaker-us-west-2-687912291502/llm/models/\n",
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz | tar -xz && mv s5cmd ChatGLM-6B/lora_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a3708e-c45b-4dac-a078-eb894844e5ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'zero_nlp'...\n",
      "remote: Enumerating objects: 569, done.\u001b[K\n",
      "remote: Counting objects: 100% (268/268), done.\u001b[K\n",
      "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
      "remote: Total 569 (delta 174), reused 191 (delta 100), pack-reused 301\u001b[K\n",
      "Receiving objects: 100% (569/569), 29.07 MiB | 23.09 MiB/s, done.\n",
      "Resolving deltas: 100% (316/316), done.\n",
      "total 208\n",
      "drwxrwxr-x 2 ec2-user ec2-user   4096 May  3 08:23 images\n",
      "-rw-rw-r-- 1 ec2-user ec2-user   3681 May  3 08:23 readme.md\n",
      "drwxrwxr-x 2 ec2-user ec2-user   4096 May  3 08:23 thuglm\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  11564 May  3 08:23 train_model_all.py\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 187995 May  3 08:23 MyTrainer.py\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ChatGLM-6B/lora_tuning\n",
    "!mkdir -p ChatGLM-6B/lora_tuning && cd ChatGLM-6B/lora_tuning/ && git clone https://github.com/qingyuan18/zero_nlp.git\n",
    "!cd ChatGLM-6B/lora_tuning/zero_nlp/Chatglm6b_ModelParallel/ && ls -lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7bb78-40a0-4514-90aa-bf09da98bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hikariming/alpaca_chinese_dataset.git\n",
    "!rm -rf alpaca_chinese_dataset/原始英文数据\n",
    "!ChatGLM-6B/lora_tuning/s5cmd sync alpaca_chinese_dataset/ s3://{bucket}/llm/chatglm/alpaca_chinese_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6aed1b8-baf3-4152-afbf-8acb43f6f690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processes_per_host is set to: 8\n",
      "{'transformer.word_embeddings': 0, 'transformer.layers.0': 0, 'transformer.layers.1': 0, 'transformer.layers.2': 0, 'transformer.layers.3': 0, 'transformer.layers.4': 0, 'transformer.layers.5': 0, 'transformer.layers.6': 0, 'transformer.layers.7': 1, 'transformer.layers.8': 1, 'transformer.layers.9': 1, 'transformer.layers.10': 1, 'transformer.layers.11': 1, 'transformer.layers.12': 1, 'transformer.layers.13': 1, 'transformer.layers.14': 2, 'transformer.layers.15': 2, 'transformer.layers.16': 2, 'transformer.layers.17': 2, 'transformer.layers.18': 2, 'transformer.layers.19': 2, 'transformer.layers.20': 2, 'transformer.layers.21': 3, 'transformer.layers.22': 3, 'transformer.layers.23': 3, 'transformer.layers.24': 3, 'transformer.layers.25': 3, 'transformer.layers.26': 3, 'transformer.layers.27': 3, 'transformer.final_layernorm': 1, 'lm_head': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "instance_type = 'ml.p4d.24xlarge'\n",
    "if instance_type in [\n",
    "    \"ml.p3.16xlarge\",\n",
    "    \"ml.p3dn.24xlarge\",\n",
    "    \"ml.g5.48xlarge\",\n",
    "    \"ml.p4d.24xlarge\",\n",
    "]:\n",
    "    processes_per_host = 8\n",
    "elif instance_type == \"ml.p2.16xlarge\":\n",
    "    processes_per_host = 16\n",
    "else:\n",
    "    processes_per_host = 4\n",
    "\n",
    "print(\"processes_per_host is set to:\", processes_per_host)\n",
    "\n",
    "####CUDA visible divices ##############\n",
    "CUDA_VISIBLE_DEVICES = \"\"\n",
    "for i in range(processes_per_host):\n",
    "    CUDA_VISIBLE_DEVICES = CUDA_VISIBLE_DEVICES+ str(i) + \",\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE_DEVICES[:-1]\n",
    "#print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "#####device mapping ########################\n",
    "DEVICE_MAP_DICT = {\"transformer.word_embeddings\": 0,\n",
    "                   \"transformer.layers.0\": 0,\n",
    "                   \"transformer.layers.1\": 0,\n",
    "                   \"transformer.layers.2\": 0,\n",
    "                   \"transformer.layers.3\": 0,\n",
    "                   \"transformer.layers.4\": 0,\n",
    "                   \"transformer.layers.5\": 0,\n",
    "                   \"transformer.layers.6\": 0,\n",
    "                   \"transformer.layers.7\": 1,\n",
    "                   \"transformer.layers.8\": 1,\n",
    "                   \"transformer.layers.9\": 1,\n",
    "                   \"transformer.layers.10\": 1,\n",
    "                   \"transformer.layers.11\": 1,\n",
    "                   \"transformer.layers.12\": 1,\n",
    "                   \"transformer.layers.13\": 1,\n",
    "                   \"transformer.layers.14\": 2,\n",
    "                   \"transformer.layers.15\": 2,\n",
    "                   \"transformer.layers.16\": 2,\n",
    "                   \"transformer.layers.17\": 2,\n",
    "                   \"transformer.layers.18\": 2,\n",
    "                   \"transformer.layers.19\": 2,\n",
    "                   \"transformer.layers.20\": 2,\n",
    "                   \"transformer.layers.21\": 3,\n",
    "                   \"transformer.layers.22\": 3,\n",
    "                   \"transformer.layers.23\": 3,\n",
    "                   \"transformer.layers.24\": 3,\n",
    "                   \"transformer.layers.25\": 3,\n",
    "                   \"transformer.layers.26\": 3,\n",
    "                   \"transformer.layers.27\": 3,\n",
    "                   \"transformer.final_layernorm\": 1,\n",
    "                   \"lm_head\": 1\n",
    "                   }\n",
    "\n",
    "os.environ['DEVICE_MAP_DICT']=json.dumps(DEVICE_MAP_DICT)\n",
    "device_map_dict = json.loads(os.environ['DEVICE_MAP_DICT'])\n",
    "#print(device_map_dict)\n",
    "#print((os.environ['DEVICE_MAP_DICT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3157519-4993-44f6-8d46-a896f8c64e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Training Job Name \n",
    "job_name = f'huggingface-chatglm-loRA-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "#define the model s3 path which will store your trained model asset\n",
    "#Note: you should use your real s3 path to configure model_s3_path\n",
    "model_s3_path='s3://{}/llm/models/chatglm/loRA/'.format(sagemaker_session.default_bucket())\n",
    "output_dir = '/opt/ml/model/alpaca-chinese-dataset-chatglm-6b-ft'\n",
    "model_name_or_path = 'THUDM/chatglm-6b'\n",
    "\n",
    "\n",
    "\n",
    "instance_count = 1\n",
    "#define the enviroment variables for your scripts.\n",
    "environment = {\n",
    "              'MODEL_S3_PATH'          : model_s3_path,\n",
    "              'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:32',\n",
    "              'LD_LIBRARY_PATH'        : '${LD_LIBRARY_PATH}:/opt/conda/lib/',\n",
    "              'NUM_GPUS'               : processes_per_host，\n",
    "              'MODEL_NAME_OR_PATH'     : model_name_or_path,\n",
    "              'OUTPUT_DIR'             : output_dir,\n",
    "              'MODEL_OUTPUT_S3_PATH'   : model_s3_path,\n",
    "              'DEVICE_MAP_DICT'        : DEVICE_MAP_DICT,\n",
    "              'CUDA_VISIBLE_DEVICES'   : CUDA_VISIBLE_DEVICES,\n",
    "              'DEVICE_MAP_DICT' : json.dumps(DEVICE_MAP_DICT),\n",
    "              'PER_DEVICE_TRAIN_BATCH_SIZE' : 1,\n",
    "              'PER_DEVICE_EVAL_BATCH_SIZE': 8,\n",
    "              'GRADIENT_ACCMULATION_STEPS': 8,\n",
    "              'NUM_TRAIN_EPOCHS'       : 8,\n",
    "              'SAVE_STEPS'             :20\n",
    "    \n",
    "}\n",
    "\n",
    "inputs={\n",
    "   'alpaca-chinese-dataset': f\"s3://{bucket}/llm/chatglm/alpaca_chinese_datasets/\"\n",
    "}\n",
    "\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'train_model_all.py',          # user endpoint script\n",
    "    source_dir           = 'ChatGLM-6B/lora_tuning/zero_nlp/Chatglm6b_ModelParallel',               # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type, # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    environment = environment,\n",
    ")\n",
    "huggingface_estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c512b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 完整的训练流程\n",
    "# 1. 数据基于`https://github.com/hikariming/alpaca_chinese_dataset`\n",
    "# 2. 部分代码来源于`https://github.com/27182812/ChatGLM-chinese-insturct/blob/main/finetune.py`\n",
    "# 3. 基于我之前修改的`model_chatglm.py`做的一整套教程\n",
    "# \n",
    "# ## 清洗数据\n",
    "\n",
    "# 在这里控制要使用的显卡\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# 如果没有下载这个仓库，可以使用下面命令进行clone\n",
    "\n",
    "# !git clone https://github.com/hikariming/alpaca_chinese_dataset.git\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# part 1 数据准备\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "target_dir_list = ['alpaca_chinese_dataset/其他中文问题补充/',\n",
    "                   'alpaca_chinese_dataset/翻译后的中文数据/',\n",
    "                   'alpaca_chinese_dataset/chatglm问题数据补充/',\n",
    "                   #    'alpaca_chinese_dataset/原始英文数据/'\n",
    "                   ]\n",
    "\n",
    "all_json_path = [glob(i + \"*.json\") for i in target_dir_list]\n",
    "all_json_path = list(chain(*all_json_path))\n",
    "len(all_json_path), all_json_path[:5]\n",
    "\n",
    "\n",
    "def read_json(x: str):\n",
    "    try:\n",
    "        data = pd.read_json(x)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "alldata = pd.concat([read_json(i) for i in all_json_path])\n",
    "\n",
    "genrate_data_dir = \"data3_0328\"\n",
    "genrate_data_dir = Path(genrate_data_dir)\n",
    "\n",
    "if genrate_data_dir.exists():\n",
    "    shutil.rmtree(genrate_data_dir, ignore_errors=True)\n",
    "\n",
    "os.makedirs(genrate_data_dir, exist_ok=True)\n",
    "\n",
    "alldata = alldata.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "chunk_size = 666\n",
    "\n",
    "for index, start_id in tqdm(enumerate(range(0, alldata.shape[0], chunk_size))):\n",
    "    temp_data = alldata.iloc[start_id:(start_id + chunk_size)]\n",
    "    temp_data.to_csv(genrate_data_dir.joinpath(f\"{index}.csv\"), index=False)\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# part 2 模型加载和转换\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "from thuglm.modeling_chatglm import ChatGLMForConditionalGeneration\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from typing import Optional\n",
    "import torch\n",
    "from MyTrainer import Trainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thuglm\", trust_remote_code=True)\n",
    "\n",
    "device_map_dict = {'transformer.word_embeddings': 0,\n",
    "                   'transformer.layers.0': 0,\n",
    "                   'transformer.layers.1': 0,\n",
    "                   'transformer.layers.2': 0,\n",
    "                   'transformer.layers.3': 0,\n",
    "                   'transformer.layers.4': 0,\n",
    "                   'transformer.layers.5': 0,\n",
    "                   'transformer.layers.6': 0,\n",
    "                   'transformer.layers.7': 0,\n",
    "                   'transformer.layers.8': 0,\n",
    "                   'transformer.layers.9': 0,\n",
    "                   'transformer.layers.10': 0,\n",
    "                   'transformer.layers.11': 0,\n",
    "                   'transformer.layers.12': 0,\n",
    "                   'transformer.layers.13': 0,\n",
    "                   'transformer.layers.14': 0,\n",
    "                   'transformer.layers.15': 1,\n",
    "                   'transformer.layers.16': 1,\n",
    "                   'transformer.layers.17': 1,\n",
    "                   'transformer.layers.18': 1,\n",
    "                   'transformer.layers.19': 1,\n",
    "                   'transformer.layers.20': 1,\n",
    "                   'transformer.layers.21': 1,\n",
    "                   'transformer.layers.22': 1,\n",
    "                   'transformer.layers.23': 1,\n",
    "                   'transformer.layers.24': 1,\n",
    "                   'transformer.layers.25': 1,\n",
    "                   'transformer.layers.26': 1,\n",
    "                   'transformer.layers.27': 1,\n",
    "                   'transformer.final_layernorm': 1,\n",
    "                   'lm_head': 1\n",
    "                   }\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"thuglm\", trust_remote_code=True).half().cuda()\n",
    "\n",
    "for k, v in device_map_dict.items():\n",
    "    if k == 'transformer.word_embeddings':\n",
    "        model.transformer.word_embeddings = model.transformer.word_embeddings.to(f'cuda:{v}')\n",
    "    if k.find(\"transformer.layers\") != -1:\n",
    "        sub_value = int(k.replace(\"transformer.layers.\", \"\"))\n",
    "        model.transformer.layers[sub_value] = model.transformer.layers[sub_value].to(f'cuda:{v}')\n",
    "\n",
    "    if k == \"transformer.final_layernorm\":\n",
    "        model.transformer.final_layernorm = model.transformer.final_layernorm.to(f'cuda:{v}')\n",
    "\n",
    "model.enable_input_require_grads()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1,\n",
    "    # ['dense','dense_h_to_4h','dense_4h_to_h'] # 'query_key_value',\n",
    "    target_modules=['query_key_value', ],\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "for k, v in device_map_dict.items():\n",
    "    #     if k == 'transformer.word_embeddings':\n",
    "    #         model.base_model.transformer.word_embeddings = model.base_model.transformer.word_embeddings.to(f'cuda:{v}')\n",
    "    if k.find(\"transformer.layers\") != -1:\n",
    "        sub_value = int(k.replace(\"transformer.layers.\", \"\"))\n",
    "        model.base_model.transformer.layers[sub_value].attention.query_key_value.lora_A = \\\n",
    "            model.base_model.transformer.layers[sub_value].attention.query_key_value.lora_A.to(f'cuda:{v}')\n",
    "        model.base_model.transformer.layers[sub_value].attention.query_key_value.lora_B = \\\n",
    "            model.base_model.transformer.layers[sub_value].attention.query_key_value.lora_B.to(f'cuda:{v}')\n",
    "\n",
    "########################################################################################################################\n",
    "# part 3 数据加载\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "all_file_list = glob(pathname=genrate_data_dir.joinpath(\"*.csv\").__str__())\n",
    "\n",
    "test_file_list = random.sample(all_file_list, int(len(all_file_list) * 0.25))\n",
    "train_file_list = [i for i in all_file_list if i not in test_file_list]\n",
    "train_file_list, test_file_list = train_file_list[:5], test_file_list[:5]\n",
    "\n",
    "len(train_file_list), len(test_file_list)\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        'train': train_file_list,\n",
    "        'valid': test_file_list\n",
    "    },\n",
    "    cache_dir=\"cache_data\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_masks_and_position_ids(\n",
    "        seq, seq_len, context_length, device, gmask=False, position_encoding_2d=True\n",
    "):\n",
    "    mask_position = (\n",
    "            seq_len - 2\n",
    "    )  # is equal to `seq.index(mask_token)` or `seq.index(150001)`\n",
    "    attention_mask = torch.ones((1, context_length, context_length), device=device)\n",
    "    attention_mask.tril_()\n",
    "    attention_mask[..., : mask_position - 1] = 1\n",
    "    attention_mask = (attention_mask < 0.5).bool()\n",
    "\n",
    "    if position_encoding_2d:\n",
    "        seq_length = seq_len - 1  # is equal to `seq_length = seq.index(150004)`\n",
    "        position_ids = torch.arange(context_length, dtype=torch.long, device=device)\n",
    "        if not gmask:\n",
    "            position_ids[seq_length:] = mask_position\n",
    "        block_position_ids = torch.cat(\n",
    "            (\n",
    "                torch.zeros(seq_length, dtype=torch.long, device=device),\n",
    "                torch.arange(\n",
    "                    context_length - seq_length, dtype=torch.long, device=device\n",
    "                )\n",
    "                + 1,\n",
    "            )\n",
    "        )\n",
    "        position_ids = torch.stack((position_ids, block_position_ids), dim=0)\n",
    "    else:\n",
    "        position_ids = torch.arange(context_length, dtype=torch.long, device=device)\n",
    "        if not gmask:\n",
    "            position_ids[context_length - 1:] = mask_position\n",
    "    return attention_mask, position_ids\n",
    "\n",
    "\n",
    "def data_collator(features: list) -> dict:\n",
    "    len_ids = [len(feature[\"input_ids\"]) for feature in features]\n",
    "    longest = max(len_ids) + 1\n",
    "    input_ids = []\n",
    "    attention_mask_list = []\n",
    "    position_ids_list = []\n",
    "    labels_list = []\n",
    "    for ids_l, feature in sorted(zip(len_ids, features), key=lambda x: -x[0]):\n",
    "        ids = feature[\"input_ids\"]\n",
    "        seq_len = feature[\"seq_len\"]\n",
    "        labels = (\n",
    "                [-100] * (seq_len - 1)\n",
    "                + ids[(seq_len - 1):]\n",
    "                + [tokenizer.eos_token_id]\n",
    "                + [-100] * (longest - ids_l - 1)\n",
    "        )\n",
    "        ids = ids + [tokenizer.eos_token_id] * (longest - ids_l)\n",
    "        _ids = torch.LongTensor(ids)\n",
    "        attention_mask, position_ids = get_masks_and_position_ids(\n",
    "            ids, seq_len, longest, _ids.device, gmask=False\n",
    "        )\n",
    "        labels_list.append(torch.LongTensor(labels))\n",
    "        input_ids.append(_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        position_ids_list.append(position_ids)\n",
    "    input_ids = torch.stack(input_ids)\n",
    "    labels = torch.stack(labels_list)\n",
    "    attention_mask = torch.stack(attention_mask_list)\n",
    "    position_ids = torch.stack(position_ids_list)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"position_ids\": position_ids,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    # {\"context\": context, \"target\": target}\n",
    "    example['context'] = context\n",
    "    example['target'] = target\n",
    "    return example\n",
    "\n",
    "\n",
    "max_seq_length = 1024\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    prompt = example[\"context\"]\n",
    "    target = example[\"target\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True)\n",
    "    target_ids = tokenizer.encode(\n",
    "        target, max_length=max_seq_length, truncation=True, add_special_tokens=False\n",
    "    )\n",
    "    input_ids = prompt_ids + target_ids + [tokenizer.eos_token_id]\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}\n",
    "\n",
    "\n",
    "def filter_nan(example):\n",
    "    return example['target'] is not None and example['context'] is not None\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    function=format_example, remove_columns=dataset['train'].column_names\n",
    ").filter(function=filter_nan)\n",
    "tokenized_datasets = tokenized_datasets.map(function=preprocess)\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# part 4 训练\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"modellog0040101\",\n",
    "    per_device_train_batch_size=4,  # 如果在24G显存上的显卡，可以开到4\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    logging_steps=20,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=20,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
