{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313d0ddf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.145.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.146.0.tar.gz (718 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.5/718.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (22.2.0)\n",
      "Collecting boto3<2.0,>=1.26.28\n",
      "  Downloading boto3-1.26.114-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.0.1)\n",
      "Collecting importlib-metadata<5.0,>=1.4.0\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.4.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (5.4.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (2.6.2)\n",
      "Collecting botocore<1.30.0,>=1.29.114\n",
      "  Downloading botocore-1.29.114-py3-none-any.whl (10.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema->sagemaker) (65.6.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2022.7)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.114->boto3<2.0,>=1.26.28->sagemaker) (1.26.15)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.146.0-py2.py3-none-any.whl size=964936 sha256=05e91afffd71b0c47a1a7251bf5ab6c82fc48feccf876f0ec6a1b919461468dd\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/08/f6/9a/3abd169a1b427683e78872b737fbab7831c8310fbec4c0acef\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: importlib-metadata, botocore, boto3, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.1\n",
      "    Uninstalling importlib-metadata-6.0.1:\n",
      "      Successfully uninstalled importlib-metadata-6.0.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.59\n",
      "    Uninstalling botocore-1.27.59:\n",
      "      Successfully uninstalled botocore-1.27.59\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.24.59\n",
      "    Uninstalling boto3-1.24.59:\n",
      "      Successfully uninstalled boto3-1.24.59\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.145.0\n",
      "    Uninstalling sagemaker-2.145.0:\n",
      "      Successfully uninstalled sagemaker-2.145.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-api 1.17.0 requires importlib-metadata~=6.0.0, but you have importlib-metadata 4.13.0 which is incompatible.\n",
      "jupyterlab 3.3.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.6 which is incompatible.\n",
      "jupyterlab-server 2.18.0 requires jsonschema>=4.17.3, but you have jsonschema 3.2.0 which is incompatible.\n",
      "awscli 1.27.71 requires botocore==1.29.71, but you have botocore 1.29.114 which is incompatible.\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.114 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.114 botocore-1.29.114 importlib-metadata-4.13.0 sagemaker-2.146.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker --upgrade\n",
    "import sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07aa92d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "amzn2extra-docker                                        | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 3.0 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "github_git-lfs/x86_64/signature                          |  833 B     00:00     \n",
      "github_git-lfs/x86_64/signature                          | 1.8 kB     00:00 !!! \n",
      "github_git-lfs-source/signature                          |  833 B     00:00     \n",
      "github_git-lfs-source/signature                          | 1.8 kB     00:00 !!! \n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "No packages marked for update\n",
      "Detected operating system as amzn/2.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Downloading repository file: https://packagecloud.io/install/repositories/github/git-lfs/config_file.repo?os=amzn&dist=2&source=script\n",
      "done.\n",
      "Installing pygpgme to verify GPG signatures...\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "github_git-lfs-source/signature                          |  833 B     00:00     \n",
      "github_git-lfs-source/signature                          | 1.8 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Package pygpgme-0.3-9.amzn2.0.3.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "Installing yum-utils...\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Package yum-utils-1.1.31-46.amzn2.0.1.noarch already installed and latest version\n",
      "Nothing to do\n",
      "Generating yum cache for github_git-lfs...\n",
      "Generating yum cache for github_git-lfs-source...\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Package git-lfs-3.3.0-1.el7.x86_64 already installed and latest version\n",
      "Package git-2.39.2-1.amzn2.0.1.x86_64 already installed and latest version\n",
      "Nothing to do\n"
     ]
    }
   ],
   "source": [
    "# For notebook instances (Amazon Linux)\n",
    "!sudo yum update -y\n",
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "!sudo yum install git-lfs git -y\n",
    "# For other environments (Ubuntu)\n",
    "#!sudo apt-get update -y\n",
    "#!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "#!sudo apt-get install git-lfs git -y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b22507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::687912291502:role/webui-notebook-stack-ExecutionRole-62U5FV4LJQS\n",
      "sagemaker bucket: sagemaker-us-west-2-687912291502\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bafa95b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/inference.py\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'code/inference.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36442/769917436.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code/inference.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# Helper: Mean Pooling - Take attention mask into account for correct averaging\\ndef mean_pooling(model_output, attention_mask):\\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\\n\\n\\ndef model_fn(model_dir):\\n    # Load model from HuggingFace Hub\\n    tokenizer = AutoTokenizer.from_pretrained(\\'sentence-transformers/paraphrase-multilingual-mpnet-base-v2\\')\\n    model = AutoModel.from_pretrained(\\'sentence-transformers/paraphrase-multilingual-mpnet-base-v2\\')\\n\\n    return model, tokenizer\\n\\ndef predict_fn(data, model_and_tokenizer):\\n    # destruct model and tokenizer\\n    model, tokenizer = model_and_tokenizer\\n\\n    # Tokenize sentences\\n    sentences = data.pop(\"inputs\", data)\\n    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\\'pt\\')\\n\\n    # Compute token embeddings\\n    with torch.no_grad():\\n        model_output = model(**encoded_input)\\n\\n    # Perform pooling. In this case, max pooling.\\n    sentence_embeddings = mean_pooling(model_output, encoded_input[\\'attention_mask\\'])\\n\\n\\n    # return dictonary, which will be json serializable\\n    return {\"vectors\": sentence_embeddings[0].tolist()}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2460\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2462\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'code/inference.py'"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Helper: Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def predict_fn(data, model_and_tokenizer):\n",
    "    # destruct model and tokenizer\n",
    "    model, tokenizer = model_and_tokenizer\n",
    "\n",
    "    # Tokenize sentences\n",
    "    sentences = data.pop(\"inputs\", data)\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "\n",
    "    # return dictonary, which will be json serializable\n",
    "    return {\"vectors\": sentence_embeddings[0].tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da03c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "#repository = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_id=repository.split(\"/\")[-1]\n",
    "s3_location=f\"s3://{sess.default_bucket()}/custom_inference/{model_id}/model.tar.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/$repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r code/ $model_id/code/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3882bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $model_id\n",
    "!tar zcvf model.tar.gz *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location\n",
    "#    upload: ./model.tar.gz to s3://sagemaker-us-east-1-558105141721/custom_inference/all-MiniLM-L6-v2/model.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_location,       # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.12\",  # transformers version used\n",
    "   pytorch_version=\"1.9\",        # pytorch version used\n",
    "   py_version='py38',            # python version used\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"inputs\": \"重恩.\",\n",
    "}\n",
    "\n",
    "res = predictor.predict(data=data)\n",
    "print(len(res['vectors']))\n",
    "#   {'vectors': [0.005078191868960857, -0.0036594511475414038, .....]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb79a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073406f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "import json\n",
    "\n",
    "\n",
    "class ContentHandler(ContentHandlerBase):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"vectors\"]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    # endpoint_name=\"endpoint-name\", \n",
    "    # credentials_profile_name=\"credentials-profile-name\", \n",
    "    endpoint_name=\"huggingface-pytorch-inference-2023-04-09-15-10-22-749\", \n",
    "    region_name=\"us-east-1\", \n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d55961",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query(\"中世界杯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30640e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_results = embeddings.embed_documents([\"foo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986ef3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
